AI-Labels-News-Impact

Effects of AI-Generated Labels in News Media on Confirmation Bias, Memory Retention, and Credibility Perception
Overview

This repository contains the design and planning materials for the research study titled “Effects of AI-Generated Labels in News Media on Confirmation Bias, Memory Retention, and Credibility Perception” proposed by Elboghdadi et al. The study aims to investigate how labeling news content as AI-generated or human-authored influences users' cognitive biases, memory retention, and perceptions of credibility. This project was developed as part of a cognitive psychology class and outlines the theoretical framework, experimental design, and methodological approach intended for future implementation.
Research Objectives

    Confirmation Bias: Explore how AI-generated labels affect the tendency to favor information that aligns with pre-existing beliefs.
    Memory Retention: Assess the potential impact of content labeling on the ability to recall factual details from news articles.
    Credibility Perception: Evaluate how different labels influence the perceived credibility and trustworthiness of news content.

Methodology

The proposed study employs a between-subjects experimental design with three conditions:

    AI-Generated Label: Articles marked as generated by artificial intelligence.
    Human-Authored Label: Articles marked as authored by a human writer.
    Control Condition: Articles presented without any labels.

Participants will be evaluated on:

    Attention Allocation: Measured through response times and accuracy in distractor tasks.
    Memory Retention: Assessed using recall tests with multiple-choice and short-answer questions.
    Trust Evaluation: Measured via a 7-point Likert scale survey focusing on credibility, objectivity, and reliability.

Repository Structure

AI-Labels-News-Impact/
├── README.md
├── LICENSE
├── .gitignore
├── data/
│   ├── raw/
│   ├── processed/
│   └── README.md
├── scripts/
│   ├── data_cleaning/
│   ├── analysis/
│   └── README.md
├── docs/
│   ├── paper/
│   ├── supplementary_materials/
│   └── images/
├── results/
│   ├── figures/
│   ├── tables/
│   └── images/
├── references/
│   └── bibliography.bib
└── CONTRIBUTING.md

Getting Started
Prerequisites

    Programming Languages: Python 3.x or R
    Libraries/Packages: Listed in scripts/data_cleaning/requirements.txt and scripts/analysis/requirements.txt

Installation

    Clone the Repository:

git clone https://github.com/yourusername/AI-Labels-News-Impact.git

Navigate to the Project Directory:

cd AI-Labels-News-Impact

Install Dependencies:

    pip install -r scripts/data_cleaning/requirements.txt
    pip install -r scripts/analysis/requirements.txt

Usage

    Experimental Design Documentation:
    Navigate to docs/paper/ to review the detailed experimental design, including hypotheses, variables, and procedures.

    Supplementary Materials:
    Access questionnaires, consent forms, and other planning documents in docs/supplementary_materials/.

    Scripts and Analysis Plans:
    Review planned scripts for data cleaning and analysis in the scripts/ directory. These scripts are prepared to facilitate the processing and evaluation of collected data once the experiment is conducted.

Results

Currently, the results/ directory is reserved for storing figures, tables, and analysis outputs that will be generated upon completion of the experiment. This structure ensures readiness for comprehensive documentation of future findings.
Contributing

Contributions are welcome! Please refer to the CONTRIBUTING.md file for guidelines on how to contribute to this project.
License

This project is licensed under the MIT License.
Contact

For any questions, feedback, or collaboration inquiries, please contact your.email@example.com.
